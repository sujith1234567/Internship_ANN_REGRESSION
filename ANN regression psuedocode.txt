
Problem statement: Given a dataset of car features and prices, 
build an ANN regression model that can accurately predict the sale price of a car based on its 
age, mileage, engine specifications, paint color, transmission type, number of doors, and weight. 
The model should be trained on a subset of the data and evaluated on a held-out test set, 
using appropriate performance metrics such as mean squared error or R-squared. 
The goal is to build a model that can generalize well to new, unseen cars and provide accurate price estimates for them.

The CarPricesData dataset appears to contain information about cars and their prices, with the following independent(input) features:
Age: the age of the car in months.
KM: the number of kilometers the car has been driven.
FuelType: the type of fuel used by the car (e.g. petrol, diesel, CNG).
HP: the horsepower of the car's engine.
MetColor: whether the car has a metallic paint color or not (binary feature).
Automatic: whether the car has an automatic transmission or not (binary feature).
CC: the size of the car's engine in cubic centimeters.
Doors: the number of doors on the car.
Weight: the weight of the car in kilograms.

Target variable : PRICE,
The rest of the variables are used for training the models(indepedent variables).


##data = load_dataset()

// Split dataset into training and testing sets
train_data, test_data = split_dataset(data, train_ratio)

// Preprocess the data (e.g. normalize, scale, impute missing values)
train_data_processed, test_data_processed = preprocess(train_data, test_data)

## Define the activation function (sigmoid)
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

## Define the derivative of the activation function
def sigmoid_derivative(x):
    return x * (1 - x)


## Initialize the network

input_size = X.shape[1]
hidden_size = 10
output_size = 1

input_weights = np.random.randn(input_size, hidden_size)
output_weights = np.random.randn(hidden_size, output_size)

input_bias = np.random.randn(hidden_size)
output_bias = np.random.randn(output_size)


## Train the network
learning_rate = 0.01
epochs = 1000
for i in range(epochs):
    # Forward propagation
    hidden_layer = sigmoid(np.dot(X, input_weights) + input_bias)
    output_layer = np.dot(hidden_layer, output_weights) + output_bias

    # Calculate the error
    error = y - output_layer

    # Backward propagation
    output_delta = error
    hidden_delta = output_delta.dot(output_weights.T) * sigmoid_derivative(hidden_layer)
    output_weights += learning_rate * hidden_layer.T.dot(output_delta)
    output_bias += learning_rate * np.sum(output_delta, axis=0, keepdims=True)
    input_weights += learning_rate * X.T.dot(hidden_delta)
    input_bias += learning_rate * np.sum(hidden_delta, axis=0)


# Making  predictions on new_data = np.array(...) # new input data
new_data = scaler.transform(new_data)
hidden_layer = sigmoid(np.dot(new_data, input_weights) + input_bias)
predictions = np.dot(hidden_layer, output_weights) + output_bias
















    
   












